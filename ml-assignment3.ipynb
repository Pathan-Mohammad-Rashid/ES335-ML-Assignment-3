{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports and Setup","metadata":{}},{"cell_type":"code","source":"import re, numpy as np, tensorflow as tf, matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.manifold import TSNE\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy(\"mixed_float16\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T12:37:00.446110Z","iopub.execute_input":"2025-11-04T12:37:00.446514Z","iopub.status.idle":"2025-11-04T12:37:00.451775Z","shell.execute_reply.started":"2025-11-04T12:37:00.446486Z","shell.execute_reply":"2025-11-04T12:37:00.450951Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"# Category I – War and Peace","metadata":{}},{"cell_type":"markdown","source":"## Load & Preprocess Text","metadata":{}},{"cell_type":"code","source":"url_wp = \"https://cs.stanford.edu/people/karpathy/char-rnn/warpeace_input.txt\"\ntext_wp = tf.keras.utils.get_file(\"warpeace.txt\", url_wp)\nwith open(text_wp, 'r', encoding='utf-8') as f:\n    wp_text = f.read().lower()\nwp_text = re.sub('[^a-zA-Z0-9 \\.]', ' ', wp_text)\nwp_tokens = wp_text.split()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T12:37:09.774887Z","iopub.execute_input":"2025-11-04T12:37:09.775150Z","iopub.status.idle":"2025-11-04T12:37:10.185929Z","shell.execute_reply.started":"2025-11-04T12:37:09.775130Z","shell.execute_reply":"2025-11-04T12:37:10.185076Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://cs.stanford.edu/people/karpathy/char-rnn/warpeace_input.txt\n\u001b[1m3258246/3258246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Vocabulary and Token Sequences","metadata":{}},{"cell_type":"code","source":"vocab_wp = sorted(set(wp_tokens))\nstoi_wp = {w:i for i,w in enumerate(vocab_wp)}\nitos_wp = {i:w for w,i in stoi_wp.items()}\nprint(\"Vocab size:\", len(vocab_wp))\n\nfrom collections import Counter\nc_wp = Counter(wp_tokens)\nprint(\"Top 10:\", c_wp.most_common(10))\nprint(\"Bottom 10:\", list(c_wp.items())[-10:])\n\ndef tokens_to_sequences(tokens, stoi, context=5, max_pairs=None):\n    X,y=[],[]\n    for i in range(context,len(tokens)):\n        ctx = [stoi.get(w,0) for w in tokens[i-context:i]]\n        X.append(ctx); y.append(stoi.get(tokens[i],0))\n        if max_pairs and len(X)>=max_pairs: break\n    return np.array(X), np.array(y)\n\nCONTEXT = 5\nX_wp, y_wp = tokens_to_sequences(wp_tokens, stoi_wp, context=CONTEXT)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T12:37:17.489489Z","iopub.execute_input":"2025-11-04T12:37:17.489793Z","iopub.status.idle":"2025-11-04T12:37:19.486014Z","shell.execute_reply.started":"2025-11-04T12:37:17.489772Z","shell.execute_reply":"2025-11-04T12:37:19.485388Z"}},"outputs":[{"name":"stdout","text":"Vocab size: 22982\nTop 10: [('the', 34544), ('and', 22221), ('to', 16637), ('of', 14870), ('a', 10541), ('he', 9885), ('in', 8920), ('that', 8115), ('his', 7973), ('was', 7323)]\nBottom 10: [('firmament', 1), ('joshua', 1), ('nun.', 1), ('defenders', 2), ('conceptions.', 1), ('uninvited', 1), ('strengthens', 1), ('erected.', 1), ('immovability', 1), ('unreal', 1)]\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"## Train/Validation Split","metadata":{}},{"cell_type":"code","source":"X_wp_train, X_wp_val, y_wp_train, y_wp_val = train_test_split(X_wp, y_wp, test_size=0.1, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T12:37:25.071670Z","iopub.execute_input":"2025-11-04T12:37:25.071955Z","iopub.status.idle":"2025-11-04T12:37:25.141710Z","shell.execute_reply.started":"2025-11-04T12:37:25.071934Z","shell.execute_reply":"2025-11-04T12:37:25.140885Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"## Model Builder","metadata":{}},{"cell_type":"code","source":"def build_mlp(vocab_size, context_len, embed_dim, hidden_layers, hidden_units, activation):\n    i = tf.keras.Input(shape=(context_len,))\n    x = tf.keras.layers.Embedding(vocab_size, embed_dim)(i)\n    x = tf.keras.layers.Flatten()(x)\n    for _ in range(hidden_layers):\n        x = tf.keras.layers.Dense(hidden_units, activation=activation)(x)\n    o = tf.keras.layers.Dense(vocab_size, activation='softmax', dtype='float32')(x)\n    m = tf.keras.Model(i,o)\n    m.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n    return m\n\ndef prepare_tfds(X,y):\n    ds = tf.data.Dataset.from_tensor_slices((X,y))\n    return ds.shuffle(10000).batch(512).prefetch(tf.data.AUTOTUNE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T12:37:30.195292Z","iopub.execute_input":"2025-11-04T12:37:30.195558Z","iopub.status.idle":"2025-11-04T12:37:30.201506Z","shell.execute_reply.started":"2025-11-04T12:37:30.195538Z","shell.execute_reply":"2025-11-04T12:37:30.200669Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## Train Models","metadata":{}},{"cell_type":"code","source":"EPOCHS = 200\nvariants_wp = [\n    {\"embed_dim\":32,\"hidden_layers\":1,\"hidden_units\":1024,\"activation\":\"relu\"},\n    {\"embed_dim\":64,\"hidden_layers\":1,\"hidden_units\":1024,\"activation\":\"relu\"},\n    {\"embed_dim\":64,\"hidden_layers\":2,\"hidden_units\":1024,\"activation\":\"tanh\"},\n]\n\ndef train_variants_wp(tag,Xt,yt,Xv,yv,vocab):\n    ds_t,ds_v=prepare_tfds(Xt,yt),prepare_tfds(Xv,yv)\n    res={}\n    for v in variants_wp:\n        name=f\"{tag}_emb{v['embed_dim']}_h{v['hidden_layers']}_{v['activation']}\"\n        m=build_mlp(len(vocab),CONTEXT,**v)\n        ck=f\"/kaggle/working/{name}.h5\"\n        cb=[tf.keras.callbacks.ModelCheckpoint(ck,save_best_only=True,monitor='val_loss'),\n            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=6)]\n        h=m.fit(ds_t,validation_data=ds_v,epochs=EPOCHS,verbose=1,callbacks=cb)\n        m=tf.keras.models.load_model(ck)\n        vl,va=m.evaluate(ds_v,verbose=0)\n        res[name]={\"model\":m,\"history\":h.history,\"val_loss\":vl,\"val_acc\":va}\n    return res\n\nres_wp=train_variants_wp(\"WARPEACE\",X_wp_train,y_wp_train,X_wp_val,y_wp_val,vocab_wp)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-04T12:37:36.579615Z","iopub.execute_input":"2025-11-04T12:37:36.579908Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 19ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6470e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 0.0010\nEpoch 2/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6623e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 0.0010\nEpoch 3/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.7264e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 0.0010\nEpoch 4/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6385e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 0.0010\nEpoch 5/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6034e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 0.0010\nEpoch 6/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6139e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 0.0010\nEpoch 7/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6040e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 0.0010\nEpoch 8/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.7157e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 5.0000e-04\nEpoch 9/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.5666e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 5.0000e-04\nEpoch 10/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6001e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 5.0000e-04\nEpoch 11/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.7185e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 5.0000e-04\nEpoch 12/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6310e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 5.0000e-04\nEpoch 13/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.7279e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 5.0000e-04\nEpoch 14/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6673e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 2.5000e-04\nEpoch 15/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6769e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 2.5000e-04\nEpoch 16/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6025e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 2.5000e-04\nEpoch 17/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.7267e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 2.5000e-04\nEpoch 18/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6048e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 2.5000e-04\nEpoch 19/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.7078e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 2.5000e-04\nEpoch 20/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6179e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.2500e-04\nEpoch 21/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6022e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.2500e-04\nEpoch 22/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6302e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.2500e-04\nEpoch 23/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6764e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.2500e-04\nEpoch 24/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.7200e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.2500e-04\nEpoch 25/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6656e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.2500e-04\nEpoch 26/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6035e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 6.2500e-05\nEpoch 27/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6683e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 6.2500e-05\nEpoch 28/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6787e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 6.2500e-05\nEpoch 29/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6624e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 6.2500e-05\nEpoch 30/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6638e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 6.2500e-05\nEpoch 31/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.5979e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 6.2500e-05\nEpoch 32/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6620e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 3.1250e-05\nEpoch 33/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6412e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 3.1250e-05\nEpoch 34/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6565e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 3.1250e-05\nEpoch 35/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6699e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 3.1250e-05\nEpoch 36/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.7376e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 3.1250e-05\nEpoch 37/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6134e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 3.1250e-05\nEpoch 38/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6451e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.5625e-05\nEpoch 39/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6554e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.5625e-05\nEpoch 40/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6231e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.5625e-05\nEpoch 41/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6987e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.5625e-05\nEpoch 42/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.5886e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.5625e-05\nEpoch 43/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6372e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 1.5625e-05\nEpoch 44/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6753e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 7.8125e-06\nEpoch 45/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6346e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 7.8125e-06\nEpoch 46/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.5683e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 7.8125e-06\nEpoch 47/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6077e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 7.8125e-06\nEpoch 48/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6951e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 7.8125e-06\nEpoch 49/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6079e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 7.8125e-06\nEpoch 50/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6738e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 3.9063e-06\nEpoch 51/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6922e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 3.9063e-06\nEpoch 52/200\n\u001b[1m1006/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.6398e-05 - val_loss: 10.0426 - val_sparse_categorical_accuracy: 5.2431e-05 - learning_rate: 3.9063e-06\nEpoch 53/200\n\u001b[1m 817/1006\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 10.0426 - sparse_categorical_accuracy: 2.5474e-05","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Plot Curves","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nfor n,r in res_wp.items():\n    plt.plot(r[\"history\"][\"loss\"]); plt.plot(r[\"history\"][\"val_loss\"],'--')\nplt.title(\"War & Peace: Loss\"); plt.xlabel(\"Epochs\")\nplt.subplot(1,2,2)\nfor n,r in res_wp.items():\n    plt.plot([v*100 for v in r[\"history\"][\"val_sparse_categorical_accuracy\"]])\nplt.title(\"War & Peace: Val Accuracy (%)\"); plt.xlabel(\"Epochs\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## t-SNE + Sample","metadata":{}},{"cell_type":"code","source":"best_wp=min(res_wp.items(),key=lambda x:x[1]['val_loss'])[1]['model']\nemb=best_wp.layers[1].get_weights()[0]\nidx=np.arange(min(200,len(vocab_wp)))\nemb2=TSNE(n_components=2,perplexity=30).fit_transform(emb[idx])\nplt.figure(figsize=(10,8))\nplt.scatter(emb2[:,0],emb2[:,1],c=np.random.rand(len(idx),3))\nfor i,w in enumerate(list(vocab_wp)[:len(idx)]): plt.text(emb2[i,0],emb2[i,1],w,fontsize=8)\nplt.title(\"t-SNE War & Peace\"); plt.show()\n\ndef gen_text(model,stoi,itos,seed,n=30,temp=0.8):\n    ctx=seed.split()\n    for _ in range(n):\n        x=np.array([[stoi.get(w,0) for w in ctx[-CONTEXT:]]])\n        p=model.predict(x,verbose=0)[0]\n        p=np.log(p+1e-9)/temp; p=np.exp(p)/np.sum(np.exp(p))\n        nxt=np.random.choice(len(p),p=p); ctx.append(itos[nxt])\n    return \" \".join(ctx)\n\nprint(gen_text(best_wp,stoi_wp,itos_wp,\"the prince said\",30,0.8))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Category II – Linux Code","metadata":{}},{"cell_type":"markdown","source":"## Load & Preprocess","metadata":{}},{"cell_type":"code","source":"url_lx = \"https://cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt\"\ntext_lx = tf.keras.utils.get_file(\"linux.txt\", url_lx)\nwith open(text_lx,'r',encoding='utf-8') as f: lx_text=f.read().lower()\nlx_tokens = re.findall(r\"[a-zA-Z0-9_]+|[{}();,<>!=+\\-*/#]|<NL>\", lx_text.replace('\\n',' <NL> '))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Vocabulary + Sequences","metadata":{}},{"cell_type":"code","source":"vocab_lx = sorted(set(lx_tokens))\nstoi_lx = {w:i for i,w in enumerate(vocab_lx)}\nitos_lx = {i:w for w,i in stoi_lx.items()}\nprint(\"Vocab size:\", len(vocab_lx))\nc_lx = Counter(lx_tokens)\nprint(\"Top 10:\", c_lx.most_common(10))\nprint(\"Bottom 10:\", list(c_lx.items())[-10:])\n\nX_lx, y_lx = tokens_to_sequences(lx_tokens, stoi_lx, context=CONTEXT)\nX_lx_train, X_lx_val, y_lx_train, y_lx_val = train_test_split(X_lx, y_lx, test_size=0.1, random_state=42)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train Models","metadata":{}},{"cell_type":"code","source":"variants_lx = [\n    {\"embed_dim\":32,\"hidden_layers\":1,\"hidden_units\":1024,\"activation\":\"relu\"},\n    {\"embed_dim\":64,\"hidden_layers\":1,\"hidden_units\":1024,\"activation\":\"relu\"},\n    {\"embed_dim\":64,\"hidden_layers\":2,\"hidden_units\":1024,\"activation\":\"tanh\"},\n]\n\ndef train_variants_lx(tag,Xt,yt,Xv,yv,vocab):\n    ds_t,ds_v=prepare_tfds(Xt,yt),prepare_tfds(Xv,yv)\n    res={}\n    for v in variants_lx:\n        name=f\"{tag}_emb{v['embed_dim']}_h{v['hidden_layers']}_{v['activation']}\"\n        m=build_mlp(len(vocab),CONTEXT,**v)\n        ck=f\"/kaggle/working/{name}.h5\"\n        cb=[tf.keras.callbacks.ModelCheckpoint(ck,save_best_only=True,monitor='val_loss'),\n            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=6)]\n        h=m.fit(ds_t,validation_data=ds_v,epochs=EPOCHS,verbose=1,callbacks=cb)\n        m=tf.keras.models.load_model(ck)\n        vl,va=m.evaluate(ds_v,verbose=0)\n        res[name]={\"model\":m,\"history\":h.history,\"val_loss\":vl,\"val_acc\":va}\n    return res\n\nres_lx=train_variants_lx(\"LINUX\",X_lx_train,y_lx_train,X_lx_val,y_lx_val,vocab_lx)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plot Curves","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14,5))\nplt.subplot(1,2,1)\nfor n,r in res_lx.items():\n    plt.plot(r[\"history\"][\"loss\"]); plt.plot(r[\"history\"][\"val_loss\"],'--')\nplt.title(\"Linux Code: Loss\"); plt.xlabel(\"Epochs\")\nplt.subplot(1,2,2)\nfor n,r in res_lx.items():\n    plt.plot([v*100 for v in r[\"history\"][\"val_sparse_categorical_accuracy\"]])\nplt.title(\"Linux Code: Val Accuracy (%)\"); plt.xlabel(\"Epochs\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## t-SNE + Sample","metadata":{}},{"cell_type":"code","source":"best_lx=min(res_lx.items(),key=lambda x:x[1]['val_loss'])[1]['model']\nemb=best_lx.layers[1].get_weights()[0]\nidx=np.arange(min(200,len(vocab_lx)))\nemb2=TSNE(n_components=2,perplexity=30).fit_transform(emb[idx])\nplt.figure(figsize=(10,8))\nplt.scatter(emb2[:,0],emb2[:,1],c=np.random.rand(len(idx),3))\nfor i,w in enumerate(list(vocab_lx)[:len(idx)]): plt.text(emb2[i,0],emb2[i,1],w,fontsize=8)\nplt.title(\"t-SNE Linux Code\"); plt.show()\n\nprint(gen_text(best_lx,stoi_lx,itos_lx,\"int main (\",40,0.7))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}